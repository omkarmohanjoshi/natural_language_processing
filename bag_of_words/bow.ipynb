{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "#config\n",
    "\n",
    "# define the data to be used\n",
    "dataDict = {\n",
    "    \"sentence\":[\n",
    "        \"Avengers is a great movie.\",\n",
    "        \"I love Avengers it is great.\",\n",
    "        \"Avengers is a bad movie.\",\n",
    "        \"I hate Avengers.\",\n",
    "        \"I didnt like the Avengers movie.\",\n",
    "        \"I think Avengers is a bad movie.\",\n",
    "        \"I love the movie.\",\n",
    "        \"I think it is great.\"\n",
    "    ],\n",
    "    \"sentiment\":[\n",
    "        \"good\",\n",
    "        \"good\",\n",
    "        \"bad\",\n",
    "        \"bad\",\n",
    "        \"bad\",\n",
    "        \"bad\",\n",
    "        \"good\",\n",
    "        \"good\"\n",
    "    ]\n",
    "}\n",
    "# define a list of stopwords\n",
    "stopWrds = [\"is\", \"a\", \"i\", \"it\"] \n",
    "# define model training parameters\n",
    "epochs = 30\n",
    "batchSize = 10\n",
    "# define number of dense units\n",
    "denseUnits = 50"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "#data preprocessing\n",
    "\n",
    "# import the necessary packages\n",
    "import re\n",
    "\n",
    "def preprocess(sentDf, stopWords, key=\"sentence\"):\n",
    "    # loop over all the sentences\n",
    "    for num in range(len(sentDf[key])):\n",
    "        # lowercase the string and remove punctuation\n",
    "        sentence = sentDf[key][num]\n",
    "        sentence = re.sub(\n",
    "            r\"[^a-zA-Z0-9]\", \" \", sentence.lower()\n",
    "        ).split()\n",
    "        # define a list for processed words\n",
    "        newWords = list()\n",
    "        # loop over the words in each sentence and filter out the\n",
    "        # stopwords\n",
    "        for word in sentence:\n",
    "            if word not in stopWords:\n",
    "                # append word if not a stopword    \n",
    "                newWords.append(word)\n",
    "        # replace sentence with the list of new words   \n",
    "        sentDf[key][num] = newWords\n",
    "    \n",
    "    # return the preprocessed data\n",
    "    return sentDf\n",
    "\n",
    "\n",
    "def prepare_tokenizer(df, sentKey=\"sentence\", outputKey=\"sentiment\"):\n",
    "    # counters for tokenizer indices\n",
    "    wordCounter = 0\n",
    "    labelCounter = 0\n",
    "    # create placeholder dictionaries for tokenizer\n",
    "    textDict = dict()\n",
    "    labelDict = dict()\n",
    "    # loop over the sentences\n",
    "    for entry in df[sentKey]:\n",
    "        # loop over each word and\n",
    "        # check if encountered before\n",
    "        for word in entry:\n",
    "            if word not in textDict.keys():\n",
    "                textDict[word] = wordCounter\n",
    "                # update word counter if new\n",
    "                # word is encountered\n",
    "                wordCounter += 1\n",
    "    \n",
    "    # repeat same process for labels  \n",
    "    for label in df[outputKey]:\n",
    "        if label not in labelDict.keys():\n",
    "            labelDict[label] = labelCounter\n",
    "            labelCounter += 1\n",
    "    \n",
    "    # return the dictionaries \n",
    "    return (textDict, labelDict)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "#bow\n",
    "\n",
    "#The Bag-of-Words model is a simple method for extracting features from text data.\n",
    "\n",
    "def calculate_bag_of_words(text, sentence):\n",
    "    # create a dictionary for frequency check\n",
    "    freqDict = dict.fromkeys(text, 0)\n",
    "    # loop over the words in sentences\n",
    "    for word in sentence:\n",
    "        # update word frequency\n",
    "        freqDict[word]=sentence.count(word)\n",
    "    # return dictionary \n",
    "    return freqDict"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "#tf wrapper\n",
    "\n",
    "# import the necessary packages\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "\n",
    "def tensorflow_wrap(df):\n",
    "    # create the tokenizer for sentences\n",
    "    tokenizerSentence = Tokenizer()\n",
    "    # create the tokenizer for labels\n",
    "    tokenizerLabel = Tokenizer()\n",
    "    # fit the tokenizer on the documents\n",
    "    tokenizerSentence.fit_on_texts(df[\"sentence\"])\n",
    "    # fit the tokenizer on the labels\n",
    "    tokenizerLabel.fit_on_texts(df[\"sentiment\"])\n",
    "    # create vectors using tensorflow\n",
    "    encodedData = tokenizerSentence.texts_to_matrix(\n",
    "        texts=df[\"sentence\"], mode=\"count\")\n",
    "    # add label column\n",
    "    labels = df[\"sentiment\"]\n",
    "    # correct label vectors\n",
    "    for i in range(len(labels)):\n",
    "        labels[i] = tokenizerLabel.word_index[labels[i]] - 1\n",
    "    # return data and labels\n",
    "    return (encodedData[:, 1:], labels.astype(\"float32\"))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "def build_shallow_net():\n",
    "    # define the model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(denseUnits, input_dim=10, activation=\"relu\"))\n",
    "    model.add(Dense(denseUnits, activation=\"relu\"))\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "    # compile the keras model\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    # return model\n",
    "    return model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "import pandas as pd\n",
    "\n",
    "# convert the input data dictionary to a pandas data frame\n",
    "df = pd.DataFrame.from_dict(dataDict)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "df.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(8, 2)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# preprocess the data frame and create data dictionaries\n",
    "preprocessedDf = preprocess(sentDf=df, stopWords=stopWrds)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "preprocessedDf"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[avengers, great, movie]</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[love, avengers, great]</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[avengers, bad, movie]</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[hate, avengers]</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[didnt, like, the, avengers, movie]</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[think, avengers, bad, movie]</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[love, the, movie]</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[think, great]</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              sentence sentiment\n",
       "0             [avengers, great, movie]      good\n",
       "1              [love, avengers, great]      good\n",
       "2               [avengers, bad, movie]       bad\n",
       "3                     [hate, avengers]       bad\n",
       "4  [didnt, like, the, avengers, movie]       bad\n",
       "5        [think, avengers, bad, movie]       bad\n",
       "6                   [love, the, movie]      good\n",
       "7                       [think, great]      good"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "(textDict, labelDict) = prepare_tokenizer(df)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "textDict,labelDict"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "({'avengers': 0,\n",
       "  'great': 1,\n",
       "  'movie': 2,\n",
       "  'love': 3,\n",
       "  'bad': 4,\n",
       "  'hate': 5,\n",
       "  'didnt': 6,\n",
       "  'like': 7,\n",
       "  'the': 8,\n",
       "  'think': 9},\n",
       " {'good': 0, 'bad': 1})"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# create an empty list for vectors\n",
    "freqList = list()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "for sentence in df[\"sentence\"]:\n",
    "    # create entries for each sentence and update the vector list   \n",
    "    entryFreq = calculate_bag_of_words(text=textDict,\n",
    "        sentence=sentence)\n",
    "    freqList.append(entryFreq)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "freqList"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'avengers': 1,\n",
       "  'great': 1,\n",
       "  'movie': 1,\n",
       "  'love': 0,\n",
       "  'bad': 0,\n",
       "  'hate': 0,\n",
       "  'didnt': 0,\n",
       "  'like': 0,\n",
       "  'the': 0,\n",
       "  'think': 0},\n",
       " {'avengers': 1,\n",
       "  'great': 1,\n",
       "  'movie': 0,\n",
       "  'love': 1,\n",
       "  'bad': 0,\n",
       "  'hate': 0,\n",
       "  'didnt': 0,\n",
       "  'like': 0,\n",
       "  'the': 0,\n",
       "  'think': 0},\n",
       " {'avengers': 1,\n",
       "  'great': 0,\n",
       "  'movie': 1,\n",
       "  'love': 0,\n",
       "  'bad': 1,\n",
       "  'hate': 0,\n",
       "  'didnt': 0,\n",
       "  'like': 0,\n",
       "  'the': 0,\n",
       "  'think': 0},\n",
       " {'avengers': 1,\n",
       "  'great': 0,\n",
       "  'movie': 0,\n",
       "  'love': 0,\n",
       "  'bad': 0,\n",
       "  'hate': 1,\n",
       "  'didnt': 0,\n",
       "  'like': 0,\n",
       "  'the': 0,\n",
       "  'think': 0},\n",
       " {'avengers': 1,\n",
       "  'great': 0,\n",
       "  'movie': 1,\n",
       "  'love': 0,\n",
       "  'bad': 0,\n",
       "  'hate': 0,\n",
       "  'didnt': 1,\n",
       "  'like': 1,\n",
       "  'the': 1,\n",
       "  'think': 0},\n",
       " {'avengers': 1,\n",
       "  'great': 0,\n",
       "  'movie': 1,\n",
       "  'love': 0,\n",
       "  'bad': 1,\n",
       "  'hate': 0,\n",
       "  'didnt': 0,\n",
       "  'like': 0,\n",
       "  'the': 0,\n",
       "  'think': 1},\n",
       " {'avengers': 0,\n",
       "  'great': 0,\n",
       "  'movie': 1,\n",
       "  'love': 1,\n",
       "  'bad': 0,\n",
       "  'hate': 0,\n",
       "  'didnt': 0,\n",
       "  'like': 0,\n",
       "  'the': 1,\n",
       "  'think': 0},\n",
       " {'avengers': 0,\n",
       "  'great': 1,\n",
       "  'movie': 0,\n",
       "  'love': 0,\n",
       "  'bad': 0,\n",
       "  'hate': 0,\n",
       "  'didnt': 0,\n",
       "  'like': 0,\n",
       "  'the': 0,\n",
       "  'think': 1}]"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# create an empty data frame for the vectors\n",
    "finalDf = pd.DataFrame() "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# loop over the vectors and concat them\n",
    "for vector in freqList:\n",
    "    vector = pd.DataFrame([vector])\n",
    "    finalDf = pd.concat([finalDf, vector], ignore_index=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# add label column to the final data frame\n",
    "finalDf[\"label\"] = df[\"sentiment\"]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "finalDf"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avengers</th>\n",
       "      <th>great</th>\n",
       "      <th>movie</th>\n",
       "      <th>love</th>\n",
       "      <th>bad</th>\n",
       "      <th>hate</th>\n",
       "      <th>didnt</th>\n",
       "      <th>like</th>\n",
       "      <th>the</th>\n",
       "      <th>think</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   avengers  great  movie  love  bad  hate  didnt  like  the  think label\n",
       "0         1      1      1     0    0     0      0     0    0      0  good\n",
       "1         1      1      0     1    0     0      0     0    0      0  good\n",
       "2         1      0      1     0    1     0      0     0    0      0   bad\n",
       "3         1      0      0     0    0     1      0     0    0      0   bad\n",
       "4         1      0      1     0    0     0      1     1    1      0   bad\n",
       "5         1      0      1     0    1     0      0     0    0      1   bad\n",
       "6         0      0      1     1    0     0      0     0    1      0  good\n",
       "7         0      1      0     0    0     0      0     0    0      1  good"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "# convert label into corresponding vector\n",
    "for i in range(len(finalDf[\"label\"])):\n",
    "    finalDf[\"label\"][i] = labelDict[finalDf[\"label\"][i]]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-19-e2a72293b0ac>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  finalDf[\"label\"][i] = labelDict[finalDf[\"label\"][i]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "shallowModel = build_shallow_net()\n",
    "print(\"[Info] Compiling model...\")\n",
    "# fit the Keras model on the dataset\n",
    "shallowModel.fit(\n",
    "    finalDf.iloc[:,0:10],\n",
    "    finalDf.iloc[:,10].astype(\"float32\"),\n",
    "    epochs=epochs,\n",
    "    batch_size=batchSize\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Info] Compiling model...\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 306ms/step - loss: 0.7242 - accuracy: 0.5000\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7127 - accuracy: 0.5000\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.7014 - accuracy: 0.5000\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6903 - accuracy: 0.5000\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6796 - accuracy: 0.5000\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6690 - accuracy: 0.5000\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6588 - accuracy: 0.5000\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6488 - accuracy: 0.5000\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6390 - accuracy: 0.5000\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6294 - accuracy: 0.6250\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6202 - accuracy: 0.6250\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6110 - accuracy: 0.6250\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6020 - accuracy: 0.6250\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5931 - accuracy: 0.6250\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5842 - accuracy: 0.6250\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5756 - accuracy: 0.6250\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5671 - accuracy: 0.7500\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5588 - accuracy: 0.7500\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5504 - accuracy: 0.8750\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5421 - accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5338 - accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5258 - accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5178 - accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5098 - accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5016 - accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4933 - accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4849 - accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4765 - accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4594 - accuracy: 1.0000\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f619c25fa00>"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "# create dataset using TensorFlow\n",
    "trainX, trainY = tensorflow_wrap(df)\n",
    "# initialize the new model for tf wrapped data\n",
    "tensorflowModel = build_shallow_net()\n",
    "print(\"[Info] Compiling model with tensorflow wrapped data...\")\n",
    "# fit the keras model on the tensorflow dataset\n",
    "tensorflowModel.fit(\n",
    "    trainX,\n",
    "    trainY,\n",
    "    epochs=epochs,\n",
    "    batch_size=batchSize\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Info] Compiling model with tensorflow wrapped data...\n",
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 0.7068 - accuracy: 0.5000\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6927 - accuracy: 0.5000\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6791 - accuracy: 0.5000\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6662 - accuracy: 0.5000\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6535 - accuracy: 0.5000\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6410 - accuracy: 0.5000\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6286 - accuracy: 0.6250\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6165 - accuracy: 0.7500\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6050 - accuracy: 0.7500\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5935 - accuracy: 0.7500\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5821 - accuracy: 0.7500\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5711 - accuracy: 0.8750\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5601 - accuracy: 1.0000\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5493 - accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5387 - accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5281 - accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5177 - accuracy: 1.0000\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5073 - accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4971 - accuracy: 1.0000\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4869 - accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4767 - accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4563 - accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4461 - accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4257 - accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4157 - accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4057 - accuracy: 1.0000\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3958 - accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.3859 - accuracy: 1.0000\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f61947ac1f0>"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit"
  },
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}